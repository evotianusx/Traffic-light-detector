{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictor(object):\n",
    "\n",
    "    def __init__(self,modelpath,categorypath):\n",
    "        \n",
    "        import numpy as np\n",
    "        import os\n",
    "        import six.moves.urllib as urllib\n",
    "        import sys\n",
    "        import tarfile\n",
    "        import tensorflow as tf\n",
    "        import zipfile\n",
    "        import collections\n",
    "        import numpy as np\n",
    "        \n",
    "        import PIL.ImageColor as ImageColor\n",
    "        import PIL.ImageDraw as ImageDraw\n",
    "        import PIL.ImageFont as ImageFont\n",
    "        import six\n",
    "        import tensorflow as tf\n",
    "        from collections import defaultdict\n",
    "        from io import StringIO\n",
    "        from matplotlib import pyplot as plt\n",
    "        from PIL import Image\n",
    "        \n",
    "        self.modelpath = modelpath\n",
    "#         self.labelpath = labelpath\n",
    "        self.categorypath = categorypath\n",
    "        detection_graph = tf.Graph()\n",
    "        with detection_graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "        self.graph = detection_graph\n",
    "        \n",
    "        \n",
    "        self.image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        self.boxes_tensor = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        self.scores_tensor = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        self.classes_tensor = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        self.tf = tf\n",
    "        import pickle\n",
    "        f = open(categorypath,'rb')\n",
    "        self.categories = pickle.loads(f.read())\n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    def load_image_into_numpy_array(self,image):\n",
    "        import numpy as np\n",
    "        (im_width, im_height) = image.size\n",
    "        return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "    def predict(self,image_path):\n",
    "        import PIL.Image as Image\n",
    "        import numpy as np\n",
    "        import collections\n",
    "        with self.graph.as_default():\n",
    "            with self.tf.Session(graph=self.graph) as sess:\n",
    "                image = Image.open(image_path)\n",
    "                image_np = self.load_image_into_numpy_array(image)\n",
    "                image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "                (boxes, scores, classes) = sess.run(\n",
    "                    [self.boxes_tensor, self.scores_tensor, self.classes_tensor],feed_dict={self.image_tensor: image_np_expanded})\n",
    "                box = tuple(boxes[0].tolist())\n",
    "#                 print(box)\n",
    "                ymin, xmin, ymax, xmax = box[0]\n",
    "                im_width, im_height = image.size\n",
    "                (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "                left = int(left) -20\n",
    "                right = int(right) +20\n",
    "                top = int(top) +20\n",
    "                bottom = int(bottom) -20\n",
    "                img = image.crop((left,top,right,bottom))\n",
    "                counted = collections.Counter(classes.tolist()[0])\n",
    "                indx=int(counted.most_common()[0][0])\n",
    "                pred = (self.categories[indx-1]['name'])\n",
    "                pred_score = (scores[0][0])\n",
    "                return (img,pred,pred_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = '/home/evotianus/CarND-Capstone/training/v3.pb'\n",
    "PATH_TO_LABELS = \"/home/evotianus/CarND-Capstone/training/labelmap_an.pbtxt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictor(modelpath=PATH_TO_CKPT,categorypath='./categories.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATHS = glob('/home/evotianus/CarND-Capstone/images/*.png')\n",
    "shuffle(TEST_IMAGE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,pred,preds = p.predict(TEST_IMAGE_PATHS[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABYAAABCCAIAAADcybGNAAAIbUlEQVR4nEWXza4sV1aEv4i1s6pO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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=22x66 at 0x7FF665EBA668>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yellow'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38724178"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
